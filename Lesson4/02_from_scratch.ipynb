{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5ff7d10c-8b07-4f83-97b0-ec4270bf3c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import kaggle\n",
    "import pandas as pd\n",
    "\n",
    "# Huggingface\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import TrainingArguments,Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88e1b8c-776b-4f9c-b070-74ede0b6e638",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "113d5028-049f-418c-bead-f0ff79fc3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "competition = 'us-patent-phrase-to-phrase-matching'\n",
    "path = Path(f'/root/{competition}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92abd832-c525-494a-afd4-4f3329f35c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading us-patent-phrase-to-phrase-matching.zip to /notebooks/fastai_course\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682k/682k [00:00<00:00, 76.3MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kaggle.api.competition_download_cli(competition)\n",
    "\n",
    "zipfile.ZipFile(f'{competition}.zip').extractall(path)\n",
    "! rm us-patent-phrase-to-phrase-matching.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a667cd09-9aaf-4729-b012-fc927343f9e7",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e2a6292-d988-4c7f-9bde-b0e88dc37822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0270bff9-8577-4945-ab05-bdf7ee7c1eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ef3fd41-1f61-46c4-a948-87234c8ca2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     anchor                  target context  score\n",
       "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n",
       "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebe6b7bb-dfe1-4b3e-a9d1-24ffdffa53da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context\n",
       "count              36473                        36473        36473   36473\n",
       "unique             36473                          733        29340     106\n",
       "top     37d61fd2272659b1  component composite coating  composition     H01\n",
       "freq                   1                          152           24    2186"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7543adf8-6cfe-4a98-940d-71c40726d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc2beb7c-2ebf-42f4-9cbe-084dce85b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5976794-4d15-44ea-acb2-f40aa1dc6bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba847d-9bea-4278-be38-7e4fa996b787",
   "metadata": {},
   "source": [
    "### Tokenizer: Tokenization and Numericalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbfbe311-db69-400b-8fe2-86b011f15e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://huggingface.co/models?sort=downloads&search=deberta\n",
    "model_nm = 'microsoft/deberta-v3-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7dca8b3-1923-4bab-b01b-48341ccdaee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokz = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a10c51e-2eb2-4ef1-8e1d-c0c99684010b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128001"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokz.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bafa544-a37b-4165-a790-81844567f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokz = AutoTokenizer.from_pretrained(model_nm, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "089ce378-4de5-4845-a913-6cc36e846cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokz.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "810c266b-b98c-4489-9025-344f910f3ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Hello', '▁there', ',', '▁my', '▁name', '▁is', '▁Lucas']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.tokenize(\"Hello there, my name is Lucas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3423a1a8-4bc1-4f43-978d-b41ada84855e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁TEXT',\n",
       " '1',\n",
       " ':',\n",
       " '▁A',\n",
       " '47',\n",
       " ';',\n",
       " '▁TEXT',\n",
       " '2',\n",
       " ':',\n",
       " '▁abatement',\n",
       " '▁of',\n",
       " '▁pollution',\n",
       " ';',\n",
       " '▁ANC',\n",
       " '1',\n",
       " ':',\n",
       " '▁abatement']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.tokenize(df['input'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa7d74ef-8b8a-49e3-9ec3-c3097f6a2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_func(x): return tokz(x[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "814dd0a4-aee2-4918-88ae-659e2c9cda53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8a0f6d2929489b95150d66d066590f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_ds = ds.map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2a662a3a-12bf-497c-8d82-0b119401d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Or in pandas\n",
    "# tok_ds = df.apply(tok_func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b10ca6a-2ac0-4191-bd1f-62ae0a40c71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '37d61fd2272659b1',\n",
       " 'anchor': 'abatement',\n",
       " 'target': 'abatement of pollution',\n",
       " 'context': 'A47',\n",
       " 'score': 0.5,\n",
       " 'input': 'TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement',\n",
       " 'input_ids': [1,\n",
       "  54453,\n",
       "  435,\n",
       "  294,\n",
       "  336,\n",
       "  5753,\n",
       "  346,\n",
       "  54453,\n",
       "  445,\n",
       "  294,\n",
       "  47284,\n",
       "  265,\n",
       "  6435,\n",
       "  346,\n",
       "  23702,\n",
       "  435,\n",
       "  294,\n",
       "  47284,\n",
       "  2],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "26a3ad1d-56c7-43b5-afe5-86752ed0c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the score to labels\n",
    "tok_ds = tok_ds.rename_columns({'score':'labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d680a70-ac94-436d-9c92-24ee1e5292ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 27354\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds = tok_ds.train_test_split(0.25, seed=42)\n",
    "dds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62772a3b-7191-4ce1-aaa3-31a3baeda9c4",
   "metadata": {},
   "source": [
    "### Creating test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45e84ef9-5ad0-40f9-a4e7-b61e7f6fe56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3b87e9c987490baf01e7ffa9b1554d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_df = pd.read_csv(path/'test.csv')\n",
    "\n",
    "eval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\n",
    "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e093fc-8d8d-4bab-9e88-15df970f03e4",
   "metadata": {},
   "source": [
    "### Create the model and the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2ea6915e-3e9c-4cb0-9e53-08af58ead6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "epochs = 4\n",
    "lr = 8e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "02dde099-492b-4da7-883d-62af1251310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='outputs', #where to store outputs\n",
    "    learning_rate=lr, #learning rate\n",
    "    warmup_ratio=0.1, #make sure to do something similar to one_cycle policy\n",
    "    lr_scheduler_type='cosine', #make sure to do something similar to one_cycle policy\n",
    "    fp16=True, #use mixed precision\n",
    "    evaluation_strategy=\"epoch\", #evaluate at the end of each epoch\n",
    "    per_device_train_batch_size=bs, #train batch size\n",
    "    per_device_eval_batch_size=bs*2, #eval batch size\n",
    "    num_train_epochs=epochs, #train for number of epochs\n",
    "    weight_decay=0.01,  \n",
    "    report_to='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eb676982-ad11-41bf-aecf-39c7befe18a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, 0.9999999999999999)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr(x,y): \n",
    "    '''\n",
    "    Returns the correlation coefficient between x and y (arrays)\n",
    "    '''\n",
    "    return np.corrcoef(x,y)[0][1] \n",
    "\n",
    "corr([2],[3]), corr([2,3],[3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "483fdd6d-0dac-448f-93a4-11e9945aef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    '''\n",
    "    Wrapper function to be passed into the HF Trainer\n",
    "    \n",
    "    parameters:\n",
    "        eval_preds: tuple of logits and labels\n",
    "    '''\n",
    "    logits, labels = eval_pred\n",
    "    return {'pearson': corr(logits, labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2e34a1f9-3bd9-4358-ae44-8026630275f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99a5039eddc4768a29387894db19490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/273M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_nm, \n",
    "    num_labels=1 #num_labels=1 makes this a regression problem https://stackoverflow.com/a/72510500\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dds['train'],\n",
    "    eval_dataset=dds['test'],\n",
    "    tokenizer=tokz, \n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3b5ec36f-91d9-4b92-9012-d58c131e908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, context, id, target, anchor. If input, context, id, target, anchor are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 27354\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='856' max='856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [856/856 02:31, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.024340</td>\n",
       "      <td>0.796798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025846</td>\n",
       "      <td>0.820384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.022410</td>\n",
       "      <td>0.831468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.022446</td>\n",
       "      <td>0.832298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, context, id, target, anchor. If input, context, id, target, anchor are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9119\n",
      "  Batch size = 256\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, context, id, target, anchor. If input, context, id, target, anchor are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9119\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to outputs/checkpoint-500\n",
      "Configuration saved in outputs/checkpoint-500/config.json\n",
      "Model weights saved in outputs/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-500/special_tokens_map.json\n",
      "added tokens file saved in outputs/checkpoint-500/added_tokens.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, context, id, target, anchor. If input, context, id, target, anchor are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9119\n",
      "  Batch size = 256\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, context, id, target, anchor. If input, context, id, target, anchor are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9119\n",
      "  Batch size = 256\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=856, training_loss=0.02362887380279113, metrics={'train_runtime': 152.3207, 'train_samples_per_second': 718.326, 'train_steps_per_second': 5.62, 'total_flos': 716605488222960.0, 'train_loss': 0.02362887380279113, 'epoch': 4.0})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "74df8d60-a01e-4646-93f5-70ec41664a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, context, id, target, anchor. If input, context, id, target, anchor are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 256\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(eval_ds)\n",
    "preds = preds.predictions.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a33e30d8-77de-4e1f-9b07-47ee93659ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50439453],\n",
       "       [ 0.61572266],\n",
       "       [ 0.55029297],\n",
       "       [ 0.29833984],\n",
       "       [-0.04330444],\n",
       "       [ 0.50634766],\n",
       "       [ 0.50390625],\n",
       "       [-0.01585388],\n",
       "       [ 0.24023438],\n",
       "       [ 1.10546875],\n",
       "       [ 0.25      ],\n",
       "       [ 0.23168945],\n",
       "       [ 0.73388672],\n",
       "       [ 0.90869141],\n",
       "       [ 0.78222656],\n",
       "       [ 0.44238281],\n",
       "       [ 0.27001953],\n",
       "       [-0.0479126 ],\n",
       "       [ 0.57763672],\n",
       "       [ 0.36694336],\n",
       "       [ 0.46313477],\n",
       "       [ 0.22668457],\n",
       "       [ 0.1541748 ],\n",
       "       [ 0.23083496],\n",
       "       [ 0.55566406],\n",
       "       [-0.03042603],\n",
       "       [-0.04290771],\n",
       "       [-0.03814697],\n",
       "       [-0.03372192],\n",
       "       [ 0.63330078],\n",
       "       [ 0.38012695],\n",
       "       [ 0.01074219],\n",
       "       [ 0.70654297],\n",
       "       [ 0.54589844],\n",
       "       [ 0.49487305],\n",
       "       [ 0.22790527]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "461a9f88-9218-475d-b244-eacc228e3b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.clip(preds, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7e5c550f-f8cf-4bc0-95fe-d1918a2f85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "submission = datasets.Dataset.from_dict({\n",
    "    'id': eval_ds['id'],\n",
    "    'score': preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dbe7238b-0067-4253-93f9-75715d4edb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37ae4bc2f57401a8d6b1c237060595a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1117"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f85d8-1ef1-45da-b75c-c1195039e4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3203046d-db5b-402b-9cbf-736b5cb3f931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c55f5-5819-43cc-81fc-1f85843d94f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5ce6fc2b-2d3d-43c1-b22a-0787f07c7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv(path/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bb57a49e-b9b5-4a31-a243-957476d58918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>474c874d0c07bd21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>442c114ed5c4e3c9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b8ae62ea5e1d8bdb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>faaddaf8fcba8a3f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ae0262c02566d2ce</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a8808e31641e856d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16ae4b99d3601e60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25c555ca3d5a2092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5203a36c501f1b7c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b9fdc772bb8fd61c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7aa5908a77a7ec24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>d19ef3979396d47e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fd83613b7843f5e1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2a619016908bfa45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>733979d75f59770d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6546846df17f9800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3ff0e7a35015be69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12ca31f018a2e2b9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>03ba802ed4029e4d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>c404f8b378cbb008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>78243984c02a72e4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>de51114bc0faec3e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7e3aff857f056bf9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>26c3c6dc6174b589</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b892011ab2e2cabc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8247ff562ca185cc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>c057aecbba832387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9f2279ce667b21dc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>b9ea2b06a878df6f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>79795133c30ef097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>25522ee5411e63e9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  score\n",
       "0   4112d61851461f60      0\n",
       "1   09e418c93a776564      0\n",
       "2   36baf228038e314b      0\n",
       "3   1f37ead645e7f0c8      0\n",
       "4   71a5b6ad068d531f      0\n",
       "5   474c874d0c07bd21      0\n",
       "6   442c114ed5c4e3c9      0\n",
       "7   b8ae62ea5e1d8bdb      0\n",
       "8   faaddaf8fcba8a3f      0\n",
       "9   ae0262c02566d2ce      0\n",
       "10  a8808e31641e856d      0\n",
       "11  16ae4b99d3601e60      0\n",
       "12  25c555ca3d5a2092      0\n",
       "13  5203a36c501f1b7c      0\n",
       "14  b9fdc772bb8fd61c      0\n",
       "15  7aa5908a77a7ec24      0\n",
       "16  d19ef3979396d47e      0\n",
       "17  fd83613b7843f5e1      0\n",
       "18  2a619016908bfa45      0\n",
       "19  733979d75f59770d      0\n",
       "20  6546846df17f9800      0\n",
       "21  3ff0e7a35015be69      0\n",
       "22  12ca31f018a2e2b9      0\n",
       "23  03ba802ed4029e4d      0\n",
       "24  c404f8b378cbb008      0\n",
       "25  78243984c02a72e4      0\n",
       "26  de51114bc0faec3e      0\n",
       "27  7e3aff857f056bf9      0\n",
       "28  26c3c6dc6174b589      0\n",
       "29  b892011ab2e2cabc      0\n",
       "30  8247ff562ca185cc      0\n",
       "31  c057aecbba832387      0\n",
       "32  9f2279ce667b21dc      0\n",
       "33  b9ea2b06a878df6f      0\n",
       "34  79795133c30ef097      0\n",
       "35  25522ee5411e63e9      0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667a7613-5d4b-4cca-ab06-253949e0a95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
